{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "from matplotlib import cm\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "LOGS_PATH = '../logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta utils\n",
    "\n",
    "def wrapped_json_loads(line, p):\n",
    "    try:\n",
    "        return json.loads(line.encode('utf-32-be').replace(b'\\0', b'').decode())\n",
    "    except:\n",
    "        print('this is the culprit', p, line.encode('utf-32-be').replace(b'\\0', b'').decode())\n",
    "        print('fix this in the input and rerun')\n",
    "        raise\n",
    "        \n",
    "        \n",
    "def get_exp_path(exp_id):\n",
    "    assert exp_id\n",
    "    return os.path.join(LOGS_PATH, exp_id)\n",
    "        \n",
    "\n",
    "def load_metadata(exp_path):\n",
    "    path = os.path.join(exp_path, 'metadata.json')\n",
    "    with open(path) as f:\n",
    "        d = json.load(f)\n",
    "    return d\n",
    "\n",
    "\n",
    "def load_worker_logs(exp_path, filter_funcs):\n",
    "    ranks_paths = glob.iglob(os.path.join(exp_path, 'rank_*.log'))\n",
    "    for p in ranks_paths:\n",
    "        basename = os.path.basename(p).strip('.log')\n",
    "        with open(p) as f:\n",
    "            logs = (wrapped_json_loads(line, p) for line in f)\n",
    "            for f in filter_funcs:\n",
    "                logs = filter(f, logs)\n",
    "            logs = list(logs)\n",
    "        yield basename, logs\n",
    "        \n",
    "\n",
    "def load_data(exp_id=None, exp_path=None, filter_funcs=None):\n",
    "    assert exp_id or exp_path\n",
    "    filter_funcs = filter_funcs or []\n",
    "    if not exp_path:\n",
    "        exp_path = os.path.join(LOGS_PATH, exp_id)\n",
    "    data = {}\n",
    "    data['meta'] = load_metadata(exp_path)\n",
    "    for basename, logs in load_worker_logs(exp_path, filter_funcs):\n",
    "        data[basename] = logs\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils related to validation set performance - useful for evaluating training-time evolution\n",
    "\n",
    "def make_df(exp_id, log_key, meta_keys):\n",
    "    data = load_data(exp_id)\n",
    "    gen = (\n",
    "        {\n",
    "            'rank': rank_key,\n",
    "            **{mk: data['meta'][mk]\n",
    "               for mk in meta_keys},\n",
    "            **log\n",
    "        }\n",
    "        for rank_key in data if 'rank_' in rank_key\n",
    "        for log in data[rank_key] if log_key in log\n",
    "    )\n",
    "    df = pd \\\n",
    "        .DataFrame(gen) \\\n",
    "        .sort_values(by='time', ascending=True) \\\n",
    "        .drop_duplicates(subset=['Rank', 'Update'], keep='last')\n",
    "    \n",
    "    if 'ValAcc' in df.columns:\n",
    "        df['ValAcc'] = df['ValAcc'].astype(float)        \n",
    "    return df, data['meta']\n",
    "\n",
    "\n",
    "make_valacc_df = partial(make_df, log_key='ValAcc', meta_keys=['seed'])\n",
    "make_valloss_df = partial(make_df, log_key='ValLoss', meta_keys=['seed'])\n",
    "make_trainloss_df = partial(make_df, log_key='TrainLoss', meta_keys=['seed'])\n",
    "\n",
    "def plot_valacc_evolution(exp_id, ax=None, color='blue', legend_label=None, color_idx=None, acc_range=True,\n",
    "                          smooth=0, color_palette=cm.tab20):\n",
    "    df, _ = make_valacc_df(exp_id)\n",
    "    val_accs = pd.pivot_table(df, index=['Epoch', 'Update'], columns=['name'], values='ValAcc')\n",
    "    if smooth:\n",
    "        val_accs = val_accs.rolling(smooth, min_periods=1).mean()\n",
    "    val_stats = val_accs \\\n",
    "        .apply(pd.DataFrame.describe, axis=1) \\\n",
    "        [['mean', 'min', 'max']] \\\n",
    "        .reset_index()\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1)\n",
    "    if color_idx:\n",
    "        color = color_palette(color_idx)\n",
    "    ax.plot(val_stats['Update'], val_stats['mean'], label=legend_label or 'Validation Accuracy', color=color)\n",
    "    if acc_range:\n",
    "        ax.fill_between(val_stats['Update'], val_stats['min'], val_stats['max'], facecolor=color, alpha=0.3)\n",
    "    ax.set_ylabel('Validation Accuracy', fontweight='bold')\n",
    "    ax.set_xlabel('Update', fontweight='bold')\n",
    "    return ax\n",
    "\n",
    "plot_evolution = plot_valacc_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils related to test set performance - useful for evaluating post-training performance\n",
    "\n",
    "def load_test_acc_data(exp_path):\n",
    "    filter_funcs = [\n",
    "        lambda log: 'TestAcc' in log or 'AggTestAcc' in log\n",
    "        # lambda log: 'TestAcc' in log\n",
    "    ]\n",
    "    data = load_data(exp_path=exp_path, filter_funcs=filter_funcs)\n",
    "    agg_test_acc_row = None\n",
    "    for key in data:\n",
    "        if 'rank_' in key:\n",
    "            # # because there's only one TestAcc log\n",
    "            # data[key] = data[key][0]\n",
    "            for row in data[key]:\n",
    "                if 'AggTestAcc' in row:\n",
    "                    agg_test_acc_row = row\n",
    "                    break\n",
    "            for i in range(len(data[key])):\n",
    "                if 'TestAcc' in data[key][i]:\n",
    "                    data[key] = data[key][i]\n",
    "                    break\n",
    "    if agg_test_acc_row:\n",
    "        data['agg'] = agg_test_acc_row\n",
    "    return data\n",
    "\n",
    "\n",
    "def glob_and_load_all_test_accs(exp_root='mnist'):\n",
    "    logs_path = '../logs/*'\n",
    "    exps = glob.iglob(logs_path)\n",
    "    exps = filter(lambda x: exp_root in x, exps)\n",
    "    exps = filter(lambda x: 'bak' not in x, exps)\n",
    "    test_accs = map(load_test_acc_data, exps)\n",
    "    test_accs = list(test_accs)\n",
    "    return test_accs\n",
    "\n",
    "\n",
    "def create_clean_df(exp_root='mnist'):\n",
    "    data = glob_and_load_all_test_accs(exp_root)\n",
    "    df = json_normalize(data)\n",
    "    df = df.drop(columns=[\n",
    "        'meta.anneal_factor',\n",
    "        'meta.anneal_milestones',\n",
    "        'meta.async_cuda',\n",
    "        'meta.checkpoint_interval',\n",
    "        'meta.comm_backend',\n",
    "        'meta.eval_on_gpu',\n",
    "        'meta.from_checkpoint',\n",
    "        'meta.gpu',\n",
    "        'meta.log_level', \n",
    "        'meta.log_interval',\n",
    "        'meta.log_path',\n",
    "        'meta.num_threads',\n",
    "        'meta.rank',\n",
    "        'meta.momentum_correction',\n",
    "        'meta.experiment',\n",
    "        'meta.learning_rate',\n",
    "        'meta.momentum',\n",
    "        'meta.nesterov',\n",
    "        'meta.timestamp',\n",
    "        'meta.batch_size',\n",
    "        'meta.epochs',\n",
    "    ])\n",
    "    cols = df.columns\n",
    "    cols = filter(lambda x: 'data' not in x, cols)\n",
    "    cols = filter(lambda x: 'master' not in x, cols)\n",
    "    cols = filter(lambda x: 'log' not in x or 'TestAcc' in x or 'AggTestAcc' in x, cols)\n",
    "    cols = list(cols)\n",
    "    df = df[cols]\n",
    "    renamed = {k: k.replace('meta.', '').replace('.log.', '.')\n",
    "               for k in cols}\n",
    "    df = df.rename(columns=renamed)\n",
    "    df = df.dropna(subset=['rank_0.TestAcc'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
